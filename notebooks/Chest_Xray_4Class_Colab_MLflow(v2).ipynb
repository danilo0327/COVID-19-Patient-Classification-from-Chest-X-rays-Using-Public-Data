{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a570b7eb",
   "metadata": {},
   "source": [
    "# Chest X‑ray 4‑Class Classifier + **MLflow** (Colab, PyTorch, T4 GPU)\n",
    "\n",
    "This notebook trains a classifier for **COVID**, **Lung_Opacity**, **Normal**, and **Viral Pneumonia** with **PyTorch** and tracks experiments using **MLflow** (remote or local server).  \n",
    "It supports:\n",
    "- Reading a `dataset.csv` with image paths + labels.\n",
    "- Path normalization (handles Windows paths; resolves relative to `IMAGES_ROOT`).\n",
    "- Class imbalance handling via `WeightedRandomSampler`.\n",
    "- Model variants: **Small CNN**, **ResNet‑18**, **EfficientNet‑B0**.\n",
    "- Mixed precision (AMP), early stopping, checkpoints.\n",
    "- **MLflow logging**: params, per-epoch metrics, confusion matrix & predictions as artifacts, and model via `mlflow.pytorch.log_model`.\n",
    "\n",
    "> **How to use**: Point `MLFLOW_TRACKING_URI` to your remote MLflow server (or leave blank for local); set `IMAGES_ROOT` and `CSV_PATH`; pick which models to run in `MODELS_TO_RUN`; run cells top to bottom.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0d90b6",
   "metadata": {},
   "source": [
    "## 0) Runtime & installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d12d3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title (Colab) Check GPU & install deps\n",
    "!nvidia-smi -L || true\n",
    "\n",
    "%pip -q install --upgrade pip\n",
    "%pip -q install pandas scikit-learn matplotlib seaborn tqdm tensorboard mlflow\n",
    "\n",
    "import torch, torchvision, mlflow\n",
    "print('Torch:', torch.__version__, '| Torchvision:', torchvision.__version__, '| MLflow:', mlflow.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250a70ef",
   "metadata": {},
   "source": [
    "## 1) Imports & global setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50a560e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, time, math, shutil, random, json, re\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "from torch.cuda import amp\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchvision import transforms, models\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "\n",
    "# Reproducibility\n",
    "def set_seed(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = False\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0f3383",
   "metadata": {},
   "source": [
    "## 2) Mount Drive (optional) & Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7ee3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Mount Drive (optional)\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c43c4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Configuration\n",
    "# --- Data paths ---\n",
    "IMAGES_ROOT = \"/content/drive/MyDrive/datasets/chest_xray\"  #@param {type:\"string\"}\n",
    "CSV_PATH    = \"/content/drive/MyDrive/datasets/chest_xray/dataset.csv\"  #@param {type:\"string\"}\n",
    "\n",
    "# Leave empty to auto-detect names in CSV\n",
    "LABEL_COL   = \"\"  # e.g., \"label\"\n",
    "PATH_COL    = \"\"  # e.g., \"img_path\"\n",
    "\n",
    "# --- Training hyperparams ---\n",
    "IMAGE_SIZE   = 224          #@param {type:\"integer\"}\n",
    "BATCH_SIZE   = 32           #@param {type:\"integer\"}\n",
    "EPOCHS       = 15           #@param {type:\"integer\"}\n",
    "LR           = 1e-4         #@param {type:\"number\"}\n",
    "WEIGHT_DECAY = 1e-4         #@param {type:\"number\"}\n",
    "USE_WEIGHTED_SAMPLER = True #@param {type:\"boolean\"}\n",
    "\n",
    "# Which models to run (each will become a separate MLflow run)\n",
    "MODELS_TO_RUN = [\"resnet18\", \"efficientnet_b0\", \"cnn_small\"]  #@param\n",
    "\n",
    "# --- Output dirs ---\n",
    "OUT_DIR = Path('/content/xray_runs_mlflow')\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# --- MLflow config ---\n",
    "USE_MLFLOW = True  #@param {type:\"boolean\"}\n",
    "MLFLOW_TRACKING_URI = \"http://YOUR_EC2_PUBLIC_IP:8050\"  #@param {type:\"string\"}\n",
    "MLFLOW_EXPERIMENT   = \"xray-4class\"  #@param {type:\"string\"}\n",
    "\n",
    "if USE_MLFLOW and MLFLOW_TRACKING_URI.strip():\n",
    "    mlflow.set_tracking_uri(MLFLOW_TRACKING_URI.strip())\n",
    "mlflow.set_experiment(MLFLOW_EXPERIMENT)\n",
    "\n",
    "print(\"Outputs:\", OUT_DIR)\n",
    "if USE_MLFLOW:\n",
    "    print(\"MLflow tracking URI:\", mlflow.get_tracking_uri())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6808d649",
   "metadata": {},
   "source": [
    "## 3) Load CSV & resolve image paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "befa9b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_all_images(root: Path):\n",
    "    \"\"\"Create a dict: basename -> [full_paths...] for quick fallback lookups.\"\"\"\n",
    "    idx = {}\n",
    "    for dirpath, _, filenames in os.walk(root):\n",
    "        for fn in filenames:\n",
    "            if fn.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tiff')):\n",
    "                full = str(Path(dirpath) / fn)\n",
    "                idx.setdefault(fn.lower(), []).append(full)\n",
    "    return idx\n",
    "\n",
    "def normalize_path(s: str) -> str:\n",
    "    s = str(s).strip()\n",
    "    # strip surrounding quotes\n",
    "    if len(s) >= 2 and s[0] == s[-1] and s[0] in (\"'\", '\"'):\n",
    "        s = s[1:-1]\n",
    "    s = s.replace(\"\\\\\", \"/\")\n",
    "    s = re.sub(r\"/+\", \"/\", s)\n",
    "    return s\n",
    "\n",
    "def resolve_paths(df: pd.DataFrame, images_root: Path, path_col: str):\n",
    "    images_root = Path(images_root)\n",
    "    assert images_root.exists(), f\"IMAGES_ROOT not found: {images_root}\"\n",
    "    print('Indexing images under', images_root, '...')\n",
    "    name_index = index_all_images(images_root)\n",
    "    resolved, missing = [], []\n",
    "    for p in tqdm(df[path_col].tolist(), desc='Resolving paths'):\n",
    "        p_norm = normalize_path(p)\n",
    "        cand = Path(p_norm)\n",
    "        if cand.exists():\n",
    "            resolved.append(str(cand)); continue\n",
    "        cand2 = images_root / p_norm\n",
    "        if cand2.exists():\n",
    "            resolved.append(str(cand2)); continue\n",
    "        base = os.path.basename(p_norm).lower()\n",
    "        hits = name_index.get(base, [])\n",
    "        if hits:\n",
    "            resolved.append(hits[0])\n",
    "        else:\n",
    "            resolved.append(None); missing.append(p_norm)\n",
    "    if missing:\n",
    "        print(f\"WARNING: {len(missing)} images not found. First 10:\\n\", missing[:10])\n",
    "    return resolved\n",
    "\n",
    "# Load CSV\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "print('CSV shape:', df.shape)\n",
    "print('Columns:', df.columns.tolist())\n",
    "\n",
    "# Auto-detect columns if blank\n",
    "if not PATH_COL:\n",
    "    candidates = [c for c in df.columns if c.lower() in ['img_path','path','image_path','filepath','file','filename']]\n",
    "    assert len(candidates) >= 1, \"Could not auto-detect the image path column. Set PATH_COL manually.\"\n",
    "    PATH_COL = candidates[0]\n",
    "if not LABEL_COL:\n",
    "    candidates = [c for c in df.columns if c.lower() in ['label','class','target','category']]\n",
    "    assert len(candidates) >= 1, \"Could not auto-detect the label column. Set LABEL_COL manually.\"\n",
    "    LABEL_COL = candidates[0]\n",
    "\n",
    "print('Using PATH_COL =', PATH_COL, '| LABEL_COL =', LABEL_COL)\n",
    "\n",
    "# Resolve full paths\n",
    "df['resolved_path'] = resolve_paths(df, Path(IMAGES_ROOT), PATH_COL)\n",
    "\n",
    "# Drop rows with missing images\n",
    "before = len(df)\n",
    "df = df.dropna(subset=['resolved_path']).reset_index(drop=True)\n",
    "after = len(df)\n",
    "print(f'Retained {after}/{before} rows after resolving image paths.')\n",
    "\n",
    "# Normalize labels\n",
    "df[LABEL_COL] = df[LABEL_COL].astype(str).str.strip()\n",
    "print(df[LABEL_COL].value_counts())\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a150a1",
   "metadata": {},
   "source": [
    "## 4) Split & Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9aad80",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = sorted(df[LABEL_COL].unique().tolist())\n",
    "print('Classes:', classes)\n",
    "cls_to_idx = {c:i for i,c in enumerate(classes)}\n",
    "idx_to_cls = {i:c for c,i in cls_to_idx.items()}\n",
    "\n",
    "df_train, df_temp = train_test_split(df, test_size=0.30, stratify=df[LABEL_COL], random_state=42)\n",
    "df_val, df_test   = train_test_split(df_temp, test_size=0.50, stratify=df_temp[LABEL_COL], random_state=42)\n",
    "print('Train:', df_train.shape, 'Val:', df_val.shape, 'Test:', df_test.shape)\n",
    "\n",
    "mean = [0.485, 0.456, 0.406]\n",
    "std  = [0.229, 0.224, 0.225]\n",
    "\n",
    "train_tfms = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=3),\n",
    "    transforms.RandomResizedCrop(IMAGE_SIZE, scale=(0.85, 1.0)),\n",
    "    transforms.RandomRotation(5),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std),\n",
    "])\n",
    "val_tfms = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=3),\n",
    "    transforms.Resize(int(IMAGE_SIZE * 1.14)),\n",
    "    transforms.CenterCrop(IMAGE_SIZE),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std),\n",
    "])\n",
    "\n",
    "class XRayDataset(Dataset):\n",
    "    def __init__(self, df, path_col, label_col, transforms=None, cls_to_idx=None):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.path_col = path_col\n",
    "        self.label_col = label_col\n",
    "        self.transforms = transforms\n",
    "        self.cls_to_idx = cls_to_idx\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        row = self.df.iloc[i]\n",
    "        p = row['resolved_path']\n",
    "        y = self.cls_to_idx[row[self.label_col]]\n",
    "        with Image.open(p) as img:\n",
    "            img = img.convert('L')\n",
    "        if self.transforms:\n",
    "            img = self.transforms(img)\n",
    "        return img, y\n",
    "\n",
    "train_ds = XRayDataset(df_train, 'resolved_path', LABEL_COL, transforms=train_tfms, cls_to_idx=cls_to_idx)\n",
    "val_ds   = XRayDataset(df_val,   'resolved_path', LABEL_COL, transforms=val_tfms,   cls_to_idx=cls_to_idx)\n",
    "test_ds  = XRayDataset(df_test,  'resolved_path', LABEL_COL, transforms=val_tfms,   cls_to_idx=cls_to_idx)\n",
    "\n",
    "sampler = None\n",
    "if USE_WEIGHTED_SAMPLER:\n",
    "    counts = Counter(df_train[LABEL_COL].tolist())\n",
    "    class_count = torch.tensor([counts[c] for c in classes], dtype=torch.float)\n",
    "    class_weight = 1.0 / class_count\n",
    "    sample_weights = [class_weight[cls_to_idx[label]].item() for label in df_train[LABEL_COL].tolist()]\n",
    "    sampler = WeightedRandomSampler(sample_weights, num_samples=len(sample_weights), replacement=True)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=(sampler is None), sampler=sampler, num_workers=2, pin_memory=True)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n",
    "test_loader  = DataLoader(test_ds,  batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "len(train_ds), len(val_ds), len(test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51717871",
   "metadata": {},
   "source": [
    "## 5) Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8566cb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SmallCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1), nn.BatchNorm2d(32), nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1), nn.BatchNorm2d(64), nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1), nn.BatchNorm2d(128), nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1), nn.BatchNorm2d(256), nn.ReLU(inplace=True),\n",
    "            nn.AdaptiveAvgPool2d((1,1)),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, 128), nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "def create_model(name: str, num_classes: int):\n",
    "    name = name.lower()\n",
    "    if name == 'cnn_small':\n",
    "        return SmallCNN(num_classes)\n",
    "    elif name == 'resnet18':\n",
    "        weights = models.ResNet18_Weights.DEFAULT\n",
    "        model = models.resnet18(weights=weights)\n",
    "        in_features = model.fc.in_features\n",
    "        model.fc = nn.Linear(in_features, num_classes)\n",
    "        return model\n",
    "    elif name == 'efficientnet_b0':\n",
    "        weights = models.EfficientNet_B0_Weights.DEFAULT\n",
    "        model = models.efficientnet_b0(weights=weights)\n",
    "        in_features = model.classifier[-1].in_features\n",
    "        model.classifier[-1] = nn.Linear(in_features, num_classes)\n",
    "        return model\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown model: {name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644a3971",
   "metadata": {},
   "source": [
    "## 6) Train/Eval utils + MLflow logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f607efab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion(y_true, y_pred, labels, normalize=True, save_path=None):\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=range(len(labels)))\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1, keepdims=True)\n",
    "    plt.figure(figsize=(6,5))\n",
    "    sns.heatmap(cm, annot=True, fmt='.2f' if normalize else 'd',\n",
    "                xticklabels=labels, yticklabels=labels)\n",
    "    plt.xlabel('Predicted'); plt.ylabel('True'); plt.title('Confusion Matrix')\n",
    "    plt.tight_layout()\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=180)\n",
    "    plt.show()\n",
    "\n",
    "def get_lr(optim_):\n",
    "    return optim_.param_groups[0]['lr']\n",
    "\n",
    "def train_and_log(model_name: str):\n",
    "    # Create model\n",
    "    model = create_model(model_name, num_classes=len(classes)).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=2)\n",
    "    scaler = amp.GradScaler()\n",
    "\n",
    "    # MLflow run\n",
    "    run_name = f\"{model_name}-IMG{IMAGE_SIZE}-B{BATCH_SIZE}\"\n",
    "    with mlflow.start_run(run_name=run_name, nested=False):\n",
    "        # Params\n",
    "        mlflow.log_params({\n",
    "            'model_name': model_name,\n",
    "            'image_size': IMAGE_SIZE,\n",
    "            'batch_size': BATCH_SIZE,\n",
    "            'epochs': EPOCHS,\n",
    "            'lr': LR,\n",
    "            'weight_decay': WEIGHT_DECAY,\n",
    "            'use_weighted_sampler': USE_WEIGHTED_SAMPLER,\n",
    "            'num_train': len(train_ds),\n",
    "            'num_val': len(val_ds),\n",
    "            'num_test': len(test_ds),\n",
    "        })\n",
    "        mlflow.set_tags({'framework': 'pytorch', 'task': 'xray-4class', 'device': str(device)})\n",
    "\n",
    "        # Training loop\n",
    "        best_acc = 0.0\n",
    "        patience, bad = 5, 0\n",
    "        history = {'epoch': [], 'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
    "\n",
    "        for epoch in range(1, EPOCHS+1):\n",
    "            # Train\n",
    "            model.train()\n",
    "            total_loss, correct, total = 0.0, 0, 0\n",
    "            for x, y in tqdm(train_loader, leave=False):\n",
    "                x, y = x.to(device, non_blocking=True), torch.tensor(y, device=device)\n",
    "                optimizer.zero_grad(set_to_none=True)\n",
    "                with amp.autocast():\n",
    "                    logits = model(x)\n",
    "                    loss = criterion(logits, y)\n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "\n",
    "                total_loss += loss.item() * x.size(0)\n",
    "                preds = logits.argmax(1)\n",
    "                correct += (preds == y).sum().item()\n",
    "                total += x.size(0)\n",
    "            train_loss = total_loss / total\n",
    "            train_acc = correct / total\n",
    "\n",
    "            # Val\n",
    "            model.eval()\n",
    "            total_loss, correct, total = 0.0, 0, 0\n",
    "            with torch.no_grad():\n",
    "                for x, y in tqdm(val_loader, leave=False):\n",
    "                    x, y = x.to(device, non_blocking=True), torch.tensor(y, device=device)\n",
    "                    logits = model(x)\n",
    "                    loss = criterion(logits, y)\n",
    "                    total_loss += loss.item() * x.size(0)\n",
    "                    preds = logits.argmax(1)\n",
    "                    correct += (preds == y).sum().item()\n",
    "                    total += x.size(0)\n",
    "            val_loss = total_loss / total\n",
    "            val_acc = correct / total\n",
    "\n",
    "            scheduler.step(val_acc)\n",
    "\n",
    "            # Log metrics per epoch\n",
    "            mlflow.log_metrics({'train_loss': train_loss, 'train_acc': train_acc,\n",
    "                                'val_loss': val_loss, 'val_acc': val_acc}, step=epoch)\n",
    "\n",
    "            history['epoch'].append(epoch)\n",
    "            history['train_loss'].append(train_loss); history['train_acc'].append(train_acc)\n",
    "            history['val_loss'].append(val_loss);     history['val_acc'].append(val_acc)\n",
    "\n",
    "            print(f\"Epoch {epoch}/{EPOCHS} | train: loss={train_loss:.4f} acc={train_acc:.4f} | val: loss={val_loss:.4f} acc={val_acc:.4f} | lr={get_lr(optimizer):.6f}\")\n",
    "\n",
    "            is_best = val_acc > best_acc\n",
    "            if is_best:\n",
    "                best_acc = val_acc\n",
    "                bad = 0\n",
    "                # Save best locally\n",
    "                torch.save({'epoch': epoch, 'state_dict': model.state_dict(),\n",
    "                            'val_acc': val_acc, 'classes': classes, 'model_name': model_name},\n",
    "                           OUT_DIR / f'best_{model_name}.pt')\n",
    "            else:\n",
    "                bad += 1\n",
    "\n",
    "            if bad >= patience:\n",
    "                print(f\"Early stopping. Best val acc: {best_acc:.4f}\")\n",
    "                break\n",
    "\n",
    "        # Save and log history\n",
    "        hist_path = OUT_DIR / f'history_{model_name}.json'\n",
    "        with open(hist_path, 'w') as f:\n",
    "            json.dump(history, f, indent=2)\n",
    "        mlflow.log_artifact(str(hist_path))\n",
    "\n",
    "        # Evaluate on test, log metrics + artifacts\n",
    "        y_true, y_pred = [], []\n",
    "        with torch.no_grad():\n",
    "            for x, y in tqdm(test_loader, leave=False):\n",
    "                x = x.to(device, non_blocking=True)\n",
    "                logits = model(x)\n",
    "                preds = logits.argmax(1).cpu().numpy().tolist()\n",
    "                y_pred.extend(preds)\n",
    "                y_true.extend(y)\n",
    "\n",
    "        report = classification_report(y_true, y_pred, target_names=classes, output_dict=True, digits=4)\n",
    "        # Flatten some main metrics\n",
    "        test_acc = report['accuracy']\n",
    "        mlflow.log_metrics({'test_accuracy': test_acc})\n",
    "        # per-class f1\n",
    "        for cls in classes:\n",
    "            mlflow.log_metric(f\"f1_{cls}\", report[cls]['f1-score'])\n",
    "\n",
    "        # Save & log confusion matrix figure\n",
    "        fig_path = OUT_DIR / f'confusion_{model_name}.png'\n",
    "        plot_confusion(y_true, y_pred, labels=classes, normalize=True, save_path=str(fig_path))\n",
    "        mlflow.log_artifact(str(fig_path))\n",
    "\n",
    "        # Save & log predictions CSV\n",
    "        preds_path = OUT_DIR / f'preds_{model_name}.csv'\n",
    "        pd.DataFrame({'y_true': [classes[i] for i in y_true],\n",
    "                      'y_pred': [classes[i] for i in y_pred]}).to_csv(preds_path, index=False)\n",
    "        mlflow.log_artifact(str(preds_path))\n",
    "\n",
    "        # Log class list and data split sizes\n",
    "        classes_path = OUT_DIR / f'classes_{model_name}.json'\n",
    "        with open(classes_path, 'w') as f:\n",
    "            json.dump({'classes': classes,\n",
    "                       'num_train': len(train_ds), 'num_val': len(val_ds), 'num_test': len(test_ds)}, f, indent=2)\n",
    "        mlflow.log_artifact(str(classes_path))\n",
    "\n",
    "        # Log the trained model\n",
    "        mlflow.pytorch.log_model(model, artifact_path=\"model\")\n",
    "\n",
    "        print(f\"Run finished. Best val acc: {best_acc:.4f} | Test acc: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e80ddd",
   "metadata": {},
   "source": [
    "## 7) Run experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51fbb61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name in MODELS_TO_RUN:\n",
    "    print(\"\\n\" + \"=\"*24 + f\" Running {model_name} \" + \"=\"*24)\n",
    "    train_and_log(model_name)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
